{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DWqmiz5iHIve","4ddKf-z3HKum","b8QciLR9HMMk","-89RlKnRHWk7","AJiheEe5HY8b","f9kUTdtDHaIB","brODwuXVKmYW"],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyNA8/SndNNVs0KdKDQW4lw0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ===== Mount Google Drive (Colab) =====\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"5sJZ9F8tBbk2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756837541235,"user_tz":-60,"elapsed":14320,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"f7cfcff3-21fd-4e72-a33a-971a8d564f09"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# WITH CONTEXT"],"metadata":{"id":"AhpG9jsOHGhd"}},{"cell_type":"markdown","source":["## Dataset Generation"],"metadata":{"id":"DWqmiz5iHIve"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrTr0iuoHAEC","executionInfo":{"status":"ok","timestamp":1756837550195,"user_tz":-60,"elapsed":2350,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"7546e8c0-389c-41f9-fe6e-dbca4f0fd5ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 128 layouts from file\n","Generating dataset ...\n"]},{"output_type":"stream","name":"stderr","text":["Generating Perfect sequences: 100%|██████████| 10000/10000 [00:00<00:00, 72929.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved .npy -> /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf\n","train.npy: 9,000 | val.npy: 1,000\n","Saved aligned meta CSV\n","Preview CSV saved: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf/flanker_matrix_perfect_pf_preview.csv\n","Saved vocab.txt\n","\n","Sanity check:\n"," - Example seq_len (should be 4*25+2 = 102): 102\n"," - Expected block_size for training: 102-1 = 101\n","\n","✅ DONE.\n"]}],"source":["# ============================================\n","# Perfect Model\n","# - Deterministic logic only (no noise)\n","# - Stimuli restricted to U/D/L/R\n","# - Vocab: U D L R A B C E 0 =>\n","# ============================================\n","\n","# ===== Imports =====\n","import os, csv, random\n","import numpy as np\n","from tqdm import tqdm\n","import pandas as pd\n","\n","# ===== Config =====\n","# I/O paths\n","LAYOUT_TXT  = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_layouts.txt\"\n","OUT_DIR     = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# Dataset parameters\n","NUM_TOTAL     = 10000       # number of sequences\n","VAL_RATIO     = 0.10        # 10% for validation\n","WINDOW_SIZE   = 4           # 4 trials -> 4*25 + '=>' + label\n","RNG_SEED      = 42          # reproducibility\n","\n","# Vocabulary\n","# 8 extra tokens + placeholder + =>\n","# Only U/D/L/R are used as stimuli\n","VOCAB_TOKENS     = ['U','D','L','R','A','B','C','E']\n","DIRECTION_TOKENS = ['U','D','L','R']\n","PLACEHOLDER      = '0'\n","CONGRUENCY_RATIO = 0.5       # P(congruent) = 0.5\n","\n","TOKENS = VOCAB_TOKENS + [PLACEHOLDER, '=>']\n","stoi = {tok:i for i,tok in enumerate(TOKENS)}\n","itos = {i:tok for tok,i in stoi.items()}\n","\n","# ===== Seed =====\n","random.seed(RNG_SEED)\n","np.random.seed(RNG_SEED)\n","\n","# ===== Load symmetric layouts =====\n","SYMMETRIC_LAYOUTS = []\n","with open(LAYOUT_TXT, \"r\") as f:\n","    for line in f:\n","        s = line.strip()\n","        if not s:\n","            continue\n","        pos = tuple(map(int, s.split(',')))\n","        assert len(pos) == 5, f\"Layout length != 5: {pos}\"\n","        assert len(set(pos)) == 5, f\"Duplicate positions: {pos}\"\n","        assert all(0 <= p < 25 for p in pos), f\"Invalid position: {pos}\"\n","        SYMMETRIC_LAYOUTS.append(pos)\n","\n","print(f\"Loaded {len(SYMMETRIC_LAYOUTS)} layouts from file\")\n","\n","# ===== Helpers =====\n","def generate_centric_matrix_trial(layout, congruent=True):\n","    \"\"\"\n","    Create a 5x5 matrix (flattened to 25 tokens).\n","    - layout[2] is the target position\n","    - flankers occupy the other 4 positions\n","    - target/flankers restricted to U/D/L/R\n","    \"\"\"\n","    mat = [PLACEHOLDER] * 25\n","\n","    target_token = random.choice(DIRECTION_TOKENS)\n","\n","    if congruent:\n","        flanker_token = target_token\n","    else:\n","        choices = [t for t in DIRECTION_TOKENS if t != target_token]\n","        flanker_token = random.choice(choices)\n","\n","    for i, p in enumerate(layout):\n","        mat[p] = target_token if i == 2 else flanker_token\n","    return mat, target_token, congruent\n","\n","def encode_sequence(trials, label_token):\n","    \"\"\"\n","    Encode: 4 trials (4*25 tokens) + '=>' + label,\n","    mapped into token IDs.\n","    \"\"\"\n","    seq = []\n","    for t in trials:\n","        seq.extend(t)\n","    seq.append('=>')\n","    seq.append(label_token)\n","    return [stoi[t] for t in seq]\n","\n","# ===== Sequence generation =====\n","def generate_sequence_matrix(window_size=4):\n","    trials, layouts, flags, labels = [], [], [], []\n","    for _ in range(window_size):\n","        layout = random.choice(SYMMETRIC_LAYOUTS)\n","        is_cong = (random.random() < CONGRUENCY_RATIO)\n","        mat, tgt, flag = generate_centric_matrix_trial(layout, congruent=is_cong)\n","        # Perfect model: no corruption/noise\n","        trials.append(mat)\n","        layouts.append(layout)\n","        flags.append(flag)\n","        labels.append(tgt)\n","    return trials, labels[-1], layouts[-1], flags[-1]  # label/metadata from trial 4\n","\n","def generate_matrix_dataset(num_sequences=10000, window_size=4):\n","    seqs, layout4, flags4 = [], [], []\n","    for _ in tqdm(range(num_sequences), desc=\"Generating Perfect sequences\"):\n","        trials, label_tok, layout_last, cong_last = generate_sequence_matrix(window_size)\n","        token_ids = encode_sequence(trials, label_tok)\n","        seqs.append(token_ids)\n","        layout4.append(layout_last)\n","        flags4.append(cong_last)\n","    return seqs, layout4, flags4\n","\n","print(\"Generating dataset ...\")\n","all_sequences, all_layouts, all_congruents = generate_matrix_dataset(\n","    num_sequences=NUM_TOTAL,\n","    window_size=WINDOW_SIZE\n",")\n","\n","# ===== Shuffle & split =====\n","N = len(all_sequences)\n","perm = np.random.RandomState(RNG_SEED).permutation(N)\n","all_sequences = [all_sequences[i] for i in perm]\n","all_layouts   = [all_layouts[i]   for i in perm]\n","all_congruents= [all_congruents[i]for i in perm]\n","\n","split_idx = int(N * (1 - VAL_RATIO))\n","train_set, val_set = all_sequences[:split_idx], all_sequences[split_idx:]\n","train_layouts, val_layouts = all_layouts[:split_idx], all_layouts[split_idx:]\n","train_flags, val_flags     = all_congruents[:split_idx], all_congruents[split_idx:]\n","\n","# ===== Save .npy =====\n","np.save(os.path.join(OUT_DIR, 'train.npy'), np.array(train_set, dtype=np.int32))\n","np.save(os.path.join(OUT_DIR, 'val.npy'),   np.array(val_set,   dtype=np.int32))\n","print(f\"Saved .npy -> {OUT_DIR}\")\n","print(f\"train.npy: {len(train_set):,} | val.npy: {len(val_set):,}\")\n","\n","# ===== Save aligned meta =====\n","def layout_to_str(tup5):\n","    return \"-\".join(map(str, tup5))\n","\n","train_meta = pd.DataFrame({\n","    \"trial4_layout\":   [layout_to_str(t) for t in train_layouts],\n","    \"is_congruent\":    [int(f) for f in train_flags],\n","    \"seq_len\":         [len(s) for s in train_set],\n","})\n","val_meta = pd.DataFrame({\n","    \"trial4_layout\":   [layout_to_str(t) for t in val_layouts],\n","    \"is_congruent\":    [int(f) for f in val_flags],\n","    \"seq_len\":         [len(s) for s in val_set],\n","})\n","train_meta.to_csv(os.path.join(OUT_DIR, \"train_meta.csv\"), index=False)\n","val_meta.to_csv(os.path.join(OUT_DIR, \"val_meta.csv\"), index=False)\n","print(\"Saved aligned meta CSV\")\n","\n","# ===== Save combined CSV (optional preview) =====\n","combined_csv = os.path.join(OUT_DIR, \"flanker_matrix_perfect_pf_preview.csv\")\n","with open(combined_csv, \"w\", newline=\"\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"trial_1_4_text\", \"target_response_token_id\", \"trial4_layout\", \"is_congruent\"])\n","    for token_ids, layout, flag in zip(all_sequences, all_layouts, all_congruents):\n","        text = \" \".join([itos[i] for i in token_ids[:-2]])\n","        target_id = token_ids[-1]\n","        layout_str = layout_to_str(layout)\n","        writer.writerow([text, target_id, layout_str, int(flag)])\n","print(f\"Preview CSV saved: {combined_csv}\")\n","\n","# ===== Save vocab =====\n","with open(os.path.join(OUT_DIR, \"vocab.txt\"), \"w\") as f:\n","    f.write(\",\".join(TOKENS))\n","print(\"Saved vocab.txt\")\n","\n","# ===== Sanity check =====\n","print(\"\\nSanity check:\")\n","print(\" - Example seq_len (should be 4*25+2 = 102):\", val_meta[\"seq_len\"].iloc[0] if len(val_meta) else \"N/A\")\n","print(\" - Expected block_size for training:\", \"102-1 = 101\")\n","print(\"\\n✅ DONE.\")"]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"4ddKf-z3HKum"}},{"cell_type":"code","source":["# ============================================\n","# Train GPT-Flanker — Perfect Model (8 tokens)\n","# - Works for both context (seq_len=102) and no-context (seq_len=27)\n","# - Auto-detect block_size from dataset\n","# - Load vocab directly from dataset's vocab.txt\n","# ============================================\n","\n","# ===== Imports =====\n","import os, sys\n","import torch\n","import numpy as np\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","\n","# Add path so Colab can locate model.py\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Flanker-GPT')\n","from model import GPT, GPTConfig\n","\n","# ===== Paths (update as needed) =====\n","data_dir = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf\"\n","out_dir  = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/checkpoints\"\n","os.makedirs(out_dir, exist_ok=True)\n","\n","# ===== Reproducibility =====\n","random_seed = 42\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# ===== Load Dataset (.npy) =====\n","train_path = os.path.join(data_dir, 'train.npy')\n","val_path   = os.path.join(data_dir, 'val.npy')\n","assert os.path.exists(train_path) and os.path.exists(val_path), \"train.npy/val.npy not found in data_dir\"\n","\n","train_data = np.load(train_path)\n","val_data   = np.load(val_path)\n","\n","# Auto-detect sequence length & block_size\n","seq_len    = int(train_data.shape[1])     # includes label at the end\n","block_size = seq_len - 1                  # model input length (exclude label)\n","print(f\"seq_len = {seq_len} -> block_size = {block_size}\")\n","\n","# ===== Load Vocab =====\n","vocab_txt = os.path.join(data_dir, \"vocab.txt\")\n","with open(vocab_txt, \"r\") as f:\n","    TOKENS = f.read().strip().split(\",\")\n","stoi = {tok: i for i, tok in enumerate(TOKENS)}\n","itos = {i: tok for tok, i in stoi.items()}\n","vocab_size = len(TOKENS)\n","print(f\"Loaded vocab ({vocab_size} tokens): {TOKENS}\")\n","\n","# ===== Training Settings =====\n","device         = 'cuda' if torch.cuda.is_available() else 'cpu'\n","batch_size     = 64\n","max_iters      = 2000\n","eval_interval  = 200\n","learning_rate  = 3e-4\n","eval_batches   = 10  # batches used for quick loss estimate\n","\n","# ===== Mini dataloader =====\n","def get_batch(split):\n","    data = train_data if split == 'train' else val_data\n","    ix = np.random.randint(len(data), size=batch_size)\n","    # x = all but last token, y = last token (label)\n","    x = torch.tensor(np.stack([d[:-1] for d in data[ix]]), dtype=torch.long, device=device)\n","    y = torch.tensor([d[-1] for d in data[ix]], dtype=torch.long, device=device)\n","    return x, y\n","\n","# ===== Create Model =====\n","config = GPTConfig(\n","    vocab_size=vocab_size,\n","    block_size=block_size,\n","    n_layer=4,\n","    n_head=4,\n","    n_embd=128\n",")\n","model = GPT(config).to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","# ===== Eval helper =====\n","@torch.no_grad()\n","def estimate_loss():\n","    model.eval()\n","    out = {}\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_batches)\n","        for k in range(eval_batches):\n","            X, Y = get_batch(split)\n","            logits, _ = model(X)\n","            logits = logits[:, -1, :]  # predict final position only\n","            loss = F.cross_entropy(logits, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean().item()\n","    model.train()\n","    return out\n","\n","# ===== Training Loop =====\n","print(\"Training GPT-Flanker (Perfect Model, 8 tokens)...\")\n","for iter in range(max_iters):\n","    if iter % eval_interval == 0 or iter == max_iters - 1:\n","        losses = estimate_loss()\n","        print(f\"Step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    xb, yb = get_batch('train')\n","    logits, _ = model(xb)\n","    logits = logits[:, -1, :]         # predict only final token\n","    loss = F.cross_entropy(logits, yb)\n","\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    # Optional: gradient clipping to avoid exploding gradients\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    optimizer.step()\n","\n","# ===== Save Model Checkpoint =====\n","# Name checkpoint clearly to indicate perfect + context/no-context\n","ckpt_name = \"flanker_gpt_matrix_perfect_pf.pt\"  # or \"..._nocontext.pt\"\n","ckpt_path = os.path.join(out_dir, ckpt_name)\n","torch.save(model.state_dict(), ckpt_path)\n","print(f\"✅ Model saved to {ckpt_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vGRQ2kSHL8r","executionInfo":{"status":"ok","timestamp":1756837606756,"user_tz":-60,"elapsed":56558,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"c8d4616f-b3ed-41c2-adcd-e3c90fed2726"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["seq_len = 102 -> block_size = 101\n","Loaded vocab (10 tokens): ['U', 'D', 'L', 'R', 'A', 'B', 'C', 'E', '0', '=>']\n","number of parameters: 0.79M\n","Training GPT-Flanker (Perfect Model, 8 tokens)...\n","Step 0: train loss 2.2846, val loss 2.2751\n","Step 200: train loss 0.0360, val loss 0.0356\n","Step 400: train loss 0.0053, val loss 0.0053\n","Step 600: train loss 0.0025, val loss 0.0025\n","Step 800: train loss 0.0015, val loss 0.0015\n","Step 1000: train loss 0.0010, val loss 0.0010\n","Step 1200: train loss 0.0007, val loss 0.0007\n","Step 1400: train loss 0.0005, val loss 0.0005\n","Step 1600: train loss 0.0004, val loss 0.0004\n","Step 1800: train loss 0.0003, val loss 0.0003\n","Step 1999: train loss 0.0003, val loss 0.0003\n","✅ Model saved to /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/checkpoints/flanker_gpt_matrix_perfect_pf.pt\n"]}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"b8QciLR9HMMk"}},{"cell_type":"code","source":["# ============================================\n","# Evaluate GPT-Flanker — Perfect Model (8 tokens)\n","# - Responses allowed: U/D/L/R/A/B/C/E\n","# - Loads vocab from dataset\n","# - Works for both context and no-context automatically\n","# ============================================\n","\n","# ===== Imports =====\n","import os, sys, csv\n","import torch\n","import numpy as np\n","import torch.nn.functional as F\n","import pandas as pd\n","\n","# ===== Add model path =====\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Flanker-GPT')\n","from model import GPT, GPTConfig\n","\n","# ===== Settings =====\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Stopping-rule parameters\n","delta = 3\n","max_samples = 100\n","restrict_to_response_tokens = True  # restrict predictions to U/D/L/R/A/B/C/E\n","\n","# ===== Paths (update as needed) =====\n","base_dir      = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT\"\n","data_dir      = f\"{base_dir}/flanker_matrix_dataset_perfect_pf\"\n","ckpt_path     = f\"{base_dir}/checkpoints/flanker_gpt_matrix_perfect_pf.pt\"\n","val_path      = os.path.join(data_dir, \"val.npy\")\n","val_meta_path = os.path.join(data_dir, \"val_meta.csv\")\n","output_csv    = f\"{base_dir}/gpt_perfect_pf_val_predictions_8resp_delta{delta}_max{max_samples}.csv\"\n","\n","# ===== Load Vocab =====\n","vocab_txt = os.path.join(data_dir, \"vocab.txt\")\n","assert os.path.exists(vocab_txt), f\"vocab.txt not found: {vocab_txt}\"\n","with open(vocab_txt, \"r\") as f:\n","    TOKENS = f.read().strip().split(\",\")\n","\n","itos = {i: ch for i, ch in enumerate(TOKENS)}\n","stoi = {ch: i for i, ch in enumerate(TOKENS)}\n","vocab_size = len(TOKENS)\n","\n","# Responses restricted to the 8 stimulus tokens\n","response_tokens = [t for t in TOKENS if t not in ['0','=>']]\n","response_token_ids = [stoi[t] for t in response_tokens]\n","\n","print(f\"Loaded vocab ({vocab_size}): {TOKENS}\")\n","print(f\"Response tokens used for prediction (8): {response_tokens}\")\n","\n","# ===== Load Validation Data =====\n","assert os.path.exists(val_path), f\"val.npy not found: {val_path}\"\n","val_data = np.load(val_path)\n","num_val = len(val_data)\n","block_size = val_data.shape[1] - 1\n","print(f\"Loaded {num_val} validation samples | inferred block_size={block_size}\")\n","\n","# ===== Load aligned meta (val_meta.csv) =====\n","assert os.path.exists(val_meta_path), f\"val_meta.csv not found: {val_meta_path}\"\n","meta = pd.read_csv(val_meta_path)\n","assert len(meta) == num_val, f\"val_meta rows ({len(meta)}) != VAL size ({num_val})\"\n","\n","# ===== Load Trained Model =====\n","config = GPTConfig(vocab_size=vocab_size, block_size=block_size, n_layer=4, n_head=4, n_embd=128)\n","model = GPT(config).to(device)\n","model.load_state_dict(torch.load(ckpt_path, map_location=device))\n","model.eval()\n","print(\"✅ Loaded Perfect GPT Model\")\n","\n","# ===== Utils =====\n","def calculate_entropy(prob_dist_np):\n","    return -float(np.sum(prob_dist_np * np.log(prob_dist_np + 1e-12)))\n","\n","def sample_until_threshold(probs_full, delta=3, max_samples=100, restrict_ids=None):\n","    \"\"\"\n","    Sequential sampling until the gap between top and second counts >= delta.\n","    \"\"\"\n","    if restrict_ids is not None:\n","        sub = probs_full[restrict_ids]\n","        sub = sub / sub.sum()\n","        id_map = restrict_ids\n","        def draw():\n","            return id_map[torch.multinomial(sub, num_samples=1, replacement=True).item()]\n","    else:\n","        def draw():\n","            return torch.multinomial(probs_full, num_samples=1, replacement=True).item()\n","\n","    counts = {}\n","    for s in range(1, max_samples + 1):\n","        tok = draw()\n","        counts[tok] = counts.get(tok, 0) + 1\n","        sorted_pairs = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)\n","        top = sorted_pairs[0][1]\n","        second = sorted_pairs[1][1] if len(sorted_pairs) > 1 else 0\n","        gap = top - second\n","        if gap >= delta:\n","            return sorted_pairs[0][0], s, True, gap\n","\n","    # fallback: argmax over restricted or full distribution\n","    if restrict_ids is not None:\n","        winner_id = restrict_ids[torch.argmax(probs_full[restrict_ids]).item()]\n","    else:\n","        winner_id = torch.argmax(probs_full).item()\n","\n","    if counts:\n","        sorted_pairs = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)\n","        gap = sorted_pairs[0][1] - (sorted_pairs[1][1] if len(sorted_pairs) > 1 else 0)\n","    else:\n","        gap = 0\n","    return winner_id, max_samples, False, gap\n","\n","# ===== Evaluation =====\n","results = []\n","correct = 0\n","\n","for i in range(num_val):\n","    x = torch.tensor(val_data[i][:-1], dtype=torch.long, device=device).unsqueeze(0)\n","    true_id = int(val_data[i][-1])\n","    true_tok = itos[true_id]\n","\n","    with torch.no_grad():\n","        logits, _ = model(x)\n","        probs = F.softmax(logits[:, -1, :], dim=-1).squeeze(0).cpu()\n","\n","        winner_id, k_used, stopped, gap_at_stop = sample_until_threshold(\n","            probs_full=probs,\n","            delta=delta,\n","            max_samples=max_samples,\n","            restrict_ids=response_token_ids if restrict_to_response_tokens else None\n","        )\n","\n","        pred_tok = itos[winner_id]\n","        is_correct = (winner_id == true_id)\n","        if is_correct:\n","            correct += 1\n","\n","        confidence = float(probs[winner_id].item())\n","        prob_true  = float(probs[true_id].item())\n","        entropy    = calculate_entropy(probs.numpy())\n","\n","    # aligned meta info\n","    is_congruent  = int(meta.loc[i, \"is_congruent\"])\n","    trial4_layout = meta.loc[i, \"trial4_layout\"]\n","\n","    row = {\n","        \"example\": i + 1,\n","        \"true_response\": true_tok,\n","        \"predicted_response\": pred_tok,\n","        \"is_correct\": bool(is_correct),\n","\n","        \"confidence\": round(confidence, 6),\n","        \"prob_of_true_token\": round(prob_true, 6),\n","        \"entropy\": round(entropy, 6),\n","\n","        \"k_samples\": int(k_used),\n","        \"stopped_by_delta\": bool(stopped),\n","        \"gap_at_stop\": int(gap_at_stop),\n","        \"delta\": int(delta),\n","        \"max_samples\": int(max_samples),\n","\n","        \"is_congruent\": is_congruent,\n","        \"trial4_layout\": trial4_layout,\n","    }\n","\n","    # record probabilities for all vocab tokens\n","    for tok in TOKENS:\n","        row[f\"{tok}_prob\"] = round(float(probs[stoi[tok]].item()), 6)\n","\n","    results.append(row)\n","\n","# ===== Save Results =====\n","with open(output_csv, \"w\", newline=\"\") as f:\n","    writer = csv.DictWriter(f, fieldnames=list(results[0].keys()))\n","    writer.writeheader()\n","    writer.writerows(results)\n","\n","acc = correct / num_val\n","print(\"\\n✅ Stopping-rule evaluation complete.\")\n","print(f\"Accuracy = {acc * 100:.2f}% (Δ={delta}, max={max_samples})\")\n","print(f\"Saved to: {output_csv}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pd4kgRIiHNz9","executionInfo":{"status":"ok","timestamp":1756837610266,"user_tz":-60,"elapsed":3479,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"2dcb80c3-aeb5-4507-c174-58098876dc12"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded vocab (10): ['U', 'D', 'L', 'R', 'A', 'B', 'C', 'E', '0', '=>']\n","Response tokens used for prediction (8): ['U', 'D', 'L', 'R', 'A', 'B', 'C', 'E']\n","Loaded 1000 validation samples | inferred block_size=101\n","number of parameters: 0.79M\n","✅ Loaded Perfect GPT Model\n","\n","✅ Stopping-rule evaluation complete.\n","Accuracy = 100.00% (Δ=3, max=100)\n","Saved to: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_val_predictions_8resp_delta3_max100.csv\n"]}]},{"cell_type":"markdown","source":["### Evaluation Analysis"],"metadata":{"id":"8RkyrKS-HOLI"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# ===== Path to evaluation results =====\n","csv_path = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_val_predictions_8resp_delta3_max100.csv\"\n","\n","df = pd.read_csv(csv_path)\n","print(\"Rows:\", len(df))\n","print(\"Columns:\", list(df.columns))\n","\n","# ===== Check required columns =====\n","required = [\n","    \"is_congruent\", \"k_samples\", \"stopped_by_delta\", \"gap_at_stop\",\n","    \"is_correct\", \"entropy\", \"confidence\", \"delta\", \"max_samples\"\n","]\n","missing = [c for c in required if c not in df.columns]\n","print(\"Missing required columns:\", missing)\n","\n","# ===== Overall accuracy =====\n","acc_overall = df[\"is_correct\"].mean()\n","print(f\"\\nAccuracy overall: {acc_overall*100:.2f}%\")\n","\n","# ===== Helper: summarize k_samples =====\n","def summarize_k(x):\n","    q = x.quantile([0, .25, .5, .75, .95, .99]).to_dict()\n","    return {\n","        \"count\": int(x.count()),\n","        \"min\": float(x.min()),\n","        \"mean\": float(x.mean()),\n","        \"std\": float(x.std(ddof=1)),\n","        \"p25\": float(q[0.25]),\n","        \"p50\": float(q[0.5]),\n","        \"p75\": float(q[0.75]),\n","        \"p95\": float(q[0.95]),\n","        \"p99\": float(q[0.99]),\n","        \"max\": float(x.max()),\n","    }\n","\n","# ===== k_samples summaries =====\n","print(\"\\n== k_samples summary (overall) ==\")\n","print(summarize_k(df[\"k_samples\"]))\n","\n","print(\"\\n== k_samples summary by congruency ==\")\n","for flag, g in df.groupby(\"is_congruent\"):\n","    label = \"congruent\" if flag == 1 else \"incongruent\"\n","    print(f\"\\n[{label}] n={len(g)}\")\n","    print(\"Accuracy:\", round(g[\"is_correct\"].mean()*100, 2), \"%\")\n","    print(\"Entropy mean:\", round(g[\"entropy\"].mean(), 4))\n","    print(summarize_k(g[\"k_samples\"]))\n","\n","# ===== Stopping diagnostics =====\n","stop_rate = df[\"stopped_by_delta\"].mean()\n","hit_max = (df[\"k_samples\"] >= df[\"max_samples\"]).mean()\n","print(f\"\\nStopped by threshold (rate): {stop_rate*100:.2f}%\")\n","print(f\"Hit max_samples (rate): {hit_max*100:.2f}%\")\n","\n","# ===== Correlations =====\n","def safe_corr(a, b):\n","    if a.std(ddof=1) == 0 or b.std(ddof=1) == 0:\n","        return np.nan\n","    return float(np.corrcoef(a, b)[0, 1])\n","\n","corr_k_entropy = safe_corr(df[\"k_samples\"], df[\"entropy\"])\n","corr_k_one_minus_conf = safe_corr(df[\"k_samples\"], 1 - df[\"confidence\"])\n","print(f\"\\nCorr(k, entropy): {corr_k_entropy:.3f}\")\n","print(f\"Corr(k, 1-confidence): {corr_k_one_minus_conf:.3f}\")\n","\n","# ===== Predicted response distribution =====\n","if \"predicted_response\" in df.columns:\n","    print(\"\\nPredicted response counts (top 10):\")\n","    print(df[\"predicted_response\"].value_counts().head(10))\n","\n","# ===== Save a 100-row sample (for quick sharing/inspection) =====\n","sample_path = csv_path.replace(\".csv\", \"_SAMPLE100.csv\")\n","df.head(100).to_csv(sample_path, index=False)\n","print(\"\\nSaved sample to:\", sample_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRPw_476HQZQ","executionInfo":{"status":"ok","timestamp":1756837610758,"user_tz":-60,"elapsed":489,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"2c7ede1a-05dd-4716-98dc-1d15af00ade9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Rows: 1000\n","Columns: ['example', 'true_response', 'predicted_response', 'is_correct', 'confidence', 'prob_of_true_token', 'entropy', 'k_samples', 'stopped_by_delta', 'gap_at_stop', 'delta', 'max_samples', 'is_congruent', 'trial4_layout', 'U_prob', 'D_prob', 'L_prob', 'R_prob', 'A_prob', 'B_prob', 'C_prob', 'E_prob', '0_prob', '=>_prob']\n","Missing required columns: []\n","\n","Accuracy overall: 100.00%\n","\n","== k_samples summary (overall) ==\n","{'count': 1000, 'min': 3.0, 'mean': 3.0, 'std': 0.0, 'p25': 3.0, 'p50': 3.0, 'p75': 3.0, 'p95': 3.0, 'p99': 3.0, 'max': 3.0}\n","\n","== k_samples summary by congruency ==\n","\n","[incongruent] n=477\n","Accuracy: 100.0 %\n","Entropy mean: 0.0031\n","{'count': 477, 'min': 3.0, 'mean': 3.0, 'std': 0.0, 'p25': 3.0, 'p50': 3.0, 'p75': 3.0, 'p95': 3.0, 'p99': 3.0, 'max': 3.0}\n","\n","[congruent] n=523\n","Accuracy: 100.0 %\n","Entropy mean: 0.003\n","{'count': 523, 'min': 3.0, 'mean': 3.0, 'std': 0.0, 'p25': 3.0, 'p50': 3.0, 'p75': 3.0, 'p95': 3.0, 'p99': 3.0, 'max': 3.0}\n","\n","Stopped by threshold (rate): 100.00%\n","Hit max_samples (rate): 0.00%\n","\n","Corr(k, entropy): nan\n","Corr(k, 1-confidence): nan\n","\n","Predicted response counts (top 10):\n","predicted_response\n","U    262\n","L    251\n","R    246\n","D    241\n","Name: count, dtype: int64\n","\n","Saved sample to: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_val_predictions_8resp_delta3_max100_SAMPLE100.csv\n"]}]},{"cell_type":"markdown","source":["### Shared RT Parameters"],"metadata":{"id":"U9XW-LzI0xmt"}},{"cell_type":"code","source":["### **You should run the evaluation to export files for all models first before running this cell**\n","\n","# ===========================================\n","# Shared RT Parameters (Pooled)\n","# - Computes theta and dispersion from human RT and model k-samples\n","# - In-memory only (no saving to disk)\n","# ===========================================\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","# ---------- CONFIG ----------\n","HUMAN_META_TRAIN = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/human_dataset/train_meta.csv\"\n","HUMAN_META_VAL   = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/human_dataset/val_meta.csv\"\n","\n","MODEL_PRED_FILES = [\n","    # context versions\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_val_predictions_8resp_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v1_val_predictions_stopping_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v2_val_predictions_stopping_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v3_val_predictions_stopping_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v4_val_predictions_stopping_delta3_max100.csv\",\n","\n","    # no-context versions\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v1_nocontext_val_predictions_stopping_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v2_nocontext_val_predictions_stopping_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v3_nocontext_val_predictions_stopping_delta3_max100.csv\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_noisy_v4_nocontext_val_predictions_stopping_delta3_max100.csv\",\n","]\n","\n","# constants\n","t0 = 300.0                # ms (non-decision time)\n","TRIM_LO, TRIM_HI = 150, 3000   # human RT trimming range\n","DISPERSION_FALLBACK = 2.25     # fallback if estimation fails\n","DISPERSION_FILE_MASK = None    # optionally restrict dispersion calibration to subset of models\n","\n","\n","# ---------- Helpers ----------\n","def _maybe_trim(s, lo, hi):\n","    if lo is not None: s = s[s >= lo]\n","    if hi is not None: s = s[s <= hi]\n","    return s\n","\n","def load_human_stats(train_meta_path, val_meta_path, t0, trim_lo=None, trim_hi=None):\n","    \"\"\"Load and summarize human RT data.\"\"\"\n","    meta = pd.concat([pd.read_csv(train_meta_path), pd.read_csv(val_meta_path)], ignore_index=True)\n","    assert {\"trial4_response_time\", \"trial4_is_congruent\"}.issubset(meta.columns), \\\n","        \"human meta must contain trial4_response_time and trial4_is_congruent\"\n","    rt = meta[\"trial4_response_time\"].dropna().astype(float)\n","    cong = meta.loc[rt.index, \"trial4_is_congruent\"].astype(int)\n","    rt = _maybe_trim(rt, trim_lo, trim_hi); cong = cong.loc[rt.index]\n","    p_con = float((cong == 1).mean()); p_inc = 1.0 - p_con\n","    mu_con = float(rt[cong == 1].mean()); mu_inc = float(rt[cong == 0].mean())\n","    mu_pool = p_con * mu_con + p_inc * mu_inc\n","    var_rt_minus_t0 = float((rt - t0).var(ddof=0))\n","    return dict(p_con=p_con, p_inc=p_inc, mu_con=mu_con, mu_inc=mu_inc,\n","                mu_pool=mu_pool, var_rt_minus_t0=var_rt_minus_t0,\n","                overall_mean=float(rt.mean()), overall_std=float(rt.std(ddof=0)), n_used=int(len(rt)))\n","\n","def load_k_stats(pred_files, mask=None):\n","    \"\"\"Load k_samples from prediction CSV files.\"\"\"\n","    ks = []\n","    for fp in pred_files:\n","        bn = os.path.basename(fp)\n","        assert \"SAMPLE\" not in bn and \"_RT_mapped_\" not in bn, f\"Do not use sample or RT-mapped files: {bn}\"\n","        if mask is not None and not any(m.lower() in bn.lower() for m in mask):\n","            continue\n","        df = pd.read_csv(fp)\n","        assert \"k_samples\" in df.columns, f\"{bn} does not contain column k_samples\"\n","        ks.append(df[\"k_samples\"].astype(float).values)\n","    if not ks:\n","        raise ValueError(\"No matching prediction files found\")\n","    k_all = np.concatenate(ks, axis=0)\n","    return dict(k_mean=float(k_all.mean()), k_var=float(k_all.var(ddof=0)), n=int(k_all.size))\n","\n","def theta_from(mu_pool_human, t0, k_mean_pool):\n","    \"\"\"Compute shared theta from human mean RT and model mean k.\"\"\"\n","    if k_mean_pool <= 0:\n","        raise ValueError(\"k_mean_pool must be > 0\")\n","    return float((mu_pool_human - t0) / k_mean_pool)\n","\n","def dispersion_from(var_rt_minus_t0, theta_shared, k_mean_pool, k_var_pool):\n","    \"\"\"Compute dispersion parameter (>=1).\"\"\"\n","    # Var(RT - t0) = theta^2 * ( E[k]/disp + Var(k) )\n","    denom = (var_rt_minus_t0 / (theta_shared ** 2)) - k_var_pool\n","    if denom <= 0: return None\n","    return float(k_mean_pool / denom)\n","\n","\n","# ---------- Compute ----------\n","human = load_human_stats(HUMAN_META_TRAIN, HUMAN_META_VAL, t0, TRIM_LO, TRIM_HI)\n","k_all = load_k_stats(MODEL_PRED_FILES, mask=None)\n","\n","theta_shared = theta_from(human[\"mu_pool\"], t0, k_all[\"k_mean\"])\n","\n","if DISPERSION_FILE_MASK:\n","    k_for_disp = load_k_stats(MODEL_PRED_FILES, mask=DISPERSION_FILE_MASK)\n","else:\n","    k_for_disp = k_all\n","\n","dispersion_shared = dispersion_from(human[\"var_rt_minus_t0\"], theta_shared, k_for_disp[\"k_mean\"], k_for_disp[\"k_var\"])\n","dispersion_note = \"pooled_estimated\"\n","if dispersion_shared is None:\n","    dispersion_shared = float(DISPERSION_FALLBACK)\n","    dispersion_note = \"used_fallback\"\n","\n","# ---------- Summary ----------\n","print(\"=== Shared RT Parameters (Plan B / pooled) ===\")\n","print(f\"t0 = {t0:.2f} ms\")\n","print(f\"theta_shared = {theta_shared:.4f} ms/sample\")\n","print(f\"dispersion_shared = {dispersion_shared:.4f}  ({dispersion_note})\")\n","print(\"\\n--- Human (trimmed) ---\")\n","print(f\"n = {human['n_used']:,}\")\n","print(f\"p_con = {human['p_con']:.4f} | p_inc = {human['p_inc']:.4f}\")\n","print(f\"mu_con = {human['mu_con']:.2f} ms | mu_inc = {human['mu_inc']:.2f} ms | mu_pool = {human['mu_pool']:.2f} ms\")\n","print(f\"overall_mean = {human['overall_mean']:.2f} | overall_std = {human['overall_std']:.2f}\")\n","print(f\"Var(RT - t0) = {human['var_rt_minus_t0']:.2f}\")\n","print(\"\\n--- k pooled (all models) ---\")\n","print(f\"k_mean = {k_all['k_mean']:.6f} | k_var = {k_all['k_var']:.6f} | n = {k_all['n']:,}\")\n","\n","# Final usable variables:\n","#   t0, theta_shared, dispersion_shared\n","#   human (dict), k_all (dict), k_for_disp (dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQIu4wyU0zH8","executionInfo":{"status":"ok","timestamp":1756837625183,"user_tz":-60,"elapsed":14428,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"7289bd55-b181-4b0f-9102-31ad1703b772"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Shared RT Parameters (Plan B / pooled) ===\n","t0 = 300.00 ms\n","theta_shared = 150.9809 ms/sample\n","dispersion_shared = 2.2500  (used_fallback)\n","\n","--- Human (trimmed) ---\n","n = 1,070,284\n","p_con = 0.5014 | p_inc = 0.4986\n","mu_con = 750.51 ms | mu_inc = 826.34 ms | mu_pool = 788.32 ms\n","overall_mean = 788.32 | overall_std = 204.96\n","Var(RT - t0) = 42008.21\n","\n","--- k pooled (all models) ---\n","k_mean = 3.234300 | k_var = 2.528204 | n = 10,000\n"]}]},{"cell_type":"markdown","source":["### RT Mapping (Shared Parameters)"],"metadata":{"id":"--_OBB7-00MV"}},{"cell_type":"code","source":["# ===========================================\n","# RT Mapping with SHARED parameters (no per-condition fitting)\n","# - Uses pooled t0, theta_shared, dispersion_shared\n","# ===========================================\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","# ---------- INPUT ----------\n","in_csv = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_val_predictions_8resp_delta3_max100.csv\"\n","\n","# ---------- SHARED PARAMS (fixed across models & conditions) ----------\n","# If already defined upstream, reuse: t0, theta_shared, dispersion_shared\n","try:\n","    t0              # check if defined earlier\n","    theta_shared\n","    dispersion_shared\n","    dispersion = float(dispersion_shared)\n","except NameError:\n","    # Fallback fixed values (replace with your calibrated ones if available)\n","    t0 = 300.0               # non-decision time (ms)\n","    theta_shared = 151.0837  # ms per sample (from pooled Plan B)\n","    dispersion = 2.25        # controls variance (fallback or calibrated value)\n","\n","t0_jitter_sd = 0.0           # optional Gaussian jitter on t0\n","use_erlang = True            # True = Gamma/Erlang RT, False = linear deterministic\n","\n","# ---------- LOAD ----------\n","df = pd.read_csv(in_csv)\n","assert \"k_samples\" in df.columns, \"CSV must contain column k_samples\"\n","\n","# ---------- MAP RT ----------\n","rng = np.random.default_rng(20250809)\n","\n","def draw_rt_row(row):\n","    k = int(max(1, row[\"k_samples\"]))\n","    t0_eff = t0 + (rng.normal(0, t0_jitter_sd) if t0_jitter_sd > 0 else 0.0)\n","    if not use_erlang:\n","        # Linear deterministic mapping\n","        return float(t0_eff + k * theta_shared)\n","    # Erlang/Gamma with dispersion control:\n","    # mean = k*theta_shared, var = theta_shared^2 * (k/dispersion)\n","    shape = k * dispersion\n","    scale = theta_shared / dispersion\n","    return float(t0_eff + rng.gamma(shape=shape, scale=scale))\n","\n","df[\"rt_ms\"] = df.apply(draw_rt_row, axis=1)\n","\n","# Optional: clip to human RT reporting range\n","# df[\"rt_ms\"] = df[\"rt_ms\"].clip(150, 3000)\n","\n","# ---------- SAVE ----------\n","suffix = \"_RT_mapped_SHARED\"\n","out_csv = os.path.splitext(in_csv)[0] + f\"{suffix}.csv\"\n","df.to_csv(out_csv, index=False)\n","\n","# ---------- QUICK SUMMARY ----------\n","def summarize(s):\n","    d = s.describe(percentiles=[.25, .5, .75, .9, .95, .99])\n","    return {k: float(d[k]) for k in d.index}\n","\n","overall_pred = summarize(df[\"rt_ms\"])\n","\n","means_by_c = {}\n","gap_pred = float(\"nan\")\n","if \"is_congruent\" in df.columns:\n","    means_by_c = df.groupby(\"is_congruent\")[\"rt_ms\"].mean().to_dict()\n","    gap_pred = means_by_c.get(0, np.nan) - means_by_c.get(1, np.nan)\n","\n","print(\"\\n=== Predicted RT (SHARED params) ===\")\n","print(f\"t0 = {t0:.1f} ms | theta_shared = {theta_shared:.4f} | dispersion = {dispersion:.4f}\")\n","print(\"Overall:\", overall_pred)\n","if means_by_c:\n","    print(f\"Means by congruency: inc={means_by_c.get(0, np.nan):.2f} | con={means_by_c.get(1, np.nan):.2f} | gap={gap_pred:.2f} ms\")\n","print(\"Saved:\", out_csv)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5laUlW-w03lM","executionInfo":{"status":"ok","timestamp":1756837625667,"user_tz":-60,"elapsed":487,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"3d781d36-4604-4ea3-a232-c066847a140e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Predicted RT (SHARED params) ===\n","t0 = 300.0 ms | theta_shared = 150.9809 | dispersion = 2.2500\n","Overall: {'count': 1000.0, 'mean': 757.2537972876182, 'std': 181.32421719860798, 'min': 387.41159962527684, '25%': 633.2860700455742, '50%': 727.4402436018165, '75%': 867.9155825259757, '90%': 986.4138658246454, '95%': 1074.2149834421537, '99%': 1305.0894139486202, 'max': 1735.1704025716751}\n","Means by congruency: inc=756.32 | con=758.10 | gap=-1.78 ms\n","Saved: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_val_predictions_8resp_delta3_max100_RT_mapped_SHARED.csv\n"]}]},{"cell_type":"markdown","source":["### Congruency Effect Analysis"],"metadata":{"id":"rKKrjLAyHR4v"}},{"cell_type":"code","source":["# ===========================================\n","# Analyze Congruency Effect — Perfect Model\n","# Requires: evaluation results (with stopping rule) + RT mapping (rt_ms column)\n","# ===========================================\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, numpy as np, pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# ---------- INPUT ----------\n","base_dir = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT\"\n","pred_csv = f\"{base_dir}/gpt_perfect_pf_val_predictions_8resp_delta3_max100_RT_mapped_SHARED.csv\"\n","out_dir  = os.path.join(base_dir, \"congruency_effect_perfect\")\n","os.makedirs(out_dir, exist_ok=True)\n","\n","# Optional: human reference values for comparison\n","mu_con_human = 751.31\n","mu_inc_human = 825.40\n","\n","# ---------- LOAD ----------\n","df = pd.read_csv(pred_csv)\n","req = {\"is_congruent\",\"rt_ms\",\"is_correct\",\"entropy\",\"confidence\",\"k_samples\"}\n","missing = list(req - set(df.columns))\n","assert not missing, f\"Missing columns: {missing}\"\n","\n","# ---------- BASIC SUMMARIES ----------\n","def summ(x: pd.Series):\n","    d = x.describe(percentiles=[.25,.5,.75,.9,.95,.99])\n","    return {k: float(d[k]) for k in d.index}\n","\n","overall_rt = summ(df[\"rt_ms\"])\n","by_c = df.groupby(\"is_congruent\")[\"rt_ms\"].mean().to_dict()\n","gap_ms = by_c.get(0, np.nan) - by_c.get(1, np.nan)\n","\n","acc_overall = float(df[\"is_correct\"].mean()*100)\n","acc_by_c = (df.groupby(\"is_congruent\")[\"is_correct\"]\n","              .mean()\n","              .rename({0:\"incongruent\",1:\"congruent\"})*100)\n","\n","ent_by_c = df.groupby(\"is_congruent\")[\"entropy\"].mean().rename({0:\"incongruent\",1:\"congruent\"})\n","k_by_c   = df.groupby(\"is_congruent\")[\"k_samples\"].mean().rename({0:\"incongruent\",1:\"congruent\"})\n","\n","def cohens_d(a, b):\n","    a = np.asarray(a, dtype=float); b = np.asarray(b, dtype=float)\n","    if len(a)<2 or len(b)<2: return np.nan\n","    m1, m2 = a.mean(), b.mean()\n","    s1, s2 = a.std(ddof=1), b.std(ddof=1)\n","    sp = np.sqrt(((len(a)-1)*s1*s1 + (len(b)-1)*s2*s2)/(len(a)+len(b)-2))\n","    return (m1-m2)/sp if sp>0 else np.nan\n","\n","rt_inc = df.loc[df[\"is_congruent\"]==0, \"rt_ms\"].values\n","rt_con = df.loc[df[\"is_congruent\"]==1, \"rt_ms\"].values\n","d_eff  = cohens_d(rt_inc, rt_con)\n","\n","print(\"=== Congruency Effect (Perfect Model) ===\")\n","print(\"RT overall:\", overall_rt)\n","print(f\"RT means by congruency (ms): inc={by_c.get(0, np.nan):.2f} | con={by_c.get(1, np.nan):.2f} | gap={gap_ms:.2f}\")\n","print(f\"Cohen's d (inc - con): {d_eff:.3f}\")\n","print(f\"Accuracy overall: {acc_overall:.2f}% | by congruency (%):\\n{acc_by_c.to_string()}\")\n","print(f\"Entropy mean by congruency:\\n{ent_by_c.to_string()}\")\n","print(f\"k_samples mean by congruency:\\n{k_by_c.to_string()}\")\n","\n","# ---------- Optional: compare with human ----------\n","print(\"\\n--- vs Human targets (optional) ---\")\n","human_gap = mu_inc_human - mu_con_human\n","print(f\"Human means: con={mu_con_human:.2f} | inc={mu_inc_human:.2f} | gap={human_gap:.2f} ms\")\n","print(f\"Model deltas: Δcon={by_c.get(1, np.nan)-mu_con_human:.2f} | Δinc={by_c.get(0, np.nan)-mu_inc_human:.2f} | Δgap={gap_ms - human_gap:.2f} ms\")\n","\n","# ---------- SAVE TABLE ----------\n","rows = [\n","    {\"metric\":\"RT_overall\", **overall_rt},\n","    {\"metric\":\"RT_mean_congruent\", \"mean\": by_c.get(1, np.nan)},\n","    {\"metric\":\"RT_mean_incongruent\", \"mean\": by_c.get(0, np.nan)},\n","    {\"metric\":\"RT_gap_inc_minus_con\", \"gap_ms\": gap_ms},\n","    {\"metric\":\"Cohens_d_inc_minus_con\", \"d\": d_eff},\n","    {\"metric\":\"Accuracy_overall_%\", \"value\": acc_overall},\n","    {\"metric\":\"Accuracy_congruent_%\", \"value\": acc_by_c.get(\"congruent\", np.nan)},\n","    {\"metric\":\"Accuracy_incongruent_%\", \"value\": acc_by_c.get(\"incongruent\", np.nan)},\n","    {\"metric\":\"Entropy_mean_congruent\", \"value\": ent_by_c.get(\"congruent\", np.nan)},\n","    {\"metric\":\"Entropy_mean_incongruent\", \"value\": ent_by_c.get(\"incongruent\", np.nan)},\n","    {\"metric\":\"k_mean_congruent\", \"value\": k_by_c.get(\"congruent\", np.nan)},\n","    {\"metric\":\"k_mean_incongruent\", \"value\": k_by_c.get(\"incongruent\", np.nan)},\n","]\n","out_csv = os.path.join(out_dir, os.path.basename(pred_csv).replace(\".csv\",\"_congruency_stats.csv\"))\n","pd.DataFrame(rows).to_csv(out_csv, index=False)\n","\n","# ---------- PLOTS ----------\n","plt.figure(figsize=(6,4))\n","plt.hist(df.loc[df[\"is_congruent\"]==1, \"rt_ms\"], bins=60, alpha=0.6, label=\"congruent\")\n","plt.hist(df.loc[df[\"is_congruent\"]==0, \"rt_ms\"], bins=60, alpha=0.6, label=\"incongruent\")\n","plt.xlabel(\"RT (ms)\"); plt.ylabel(\"Count\"); plt.title(\"RT by Congruency (Histogram)\")\n","plt.legend(); plt.tight_layout()\n","plt.savefig(os.path.join(out_dir,\"rt_hist_by_congruency.png\"), dpi=160); plt.close()\n","\n","def ecdf(x):\n","    xs = np.sort(x); ys = np.arange(1, len(xs)+1)/len(xs); return xs, ys\n","x1,y1 = ecdf(rt_con); x2,y2 = ecdf(rt_inc)\n","plt.figure(figsize=(6,4))\n","plt.plot(x1,y1,label=\"congruent\"); plt.plot(x2,y2,label=\"incongruent\")\n","plt.xlabel(\"RT (ms)\"); plt.ylabel(\"CDF\"); plt.title(\"RT CDF by Congruency\")\n","plt.legend(); plt.tight_layout()\n","plt.savefig(os.path.join(out_dir,\"rt_cdf_by_congruency.png\"), dpi=160); plt.close()\n","\n","plt.figure(figsize=(5,4))\n","plt.boxplot([rt_con, rt_inc], labels=[\"congruent\",\"incongruent\"])\n","plt.ylabel(\"RT (ms)\"); plt.title(\"RT Boxplot by Congruency\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(out_dir,\"rt_box_by_congruency.png\"), dpi=160); plt.close()\n","\n","print(\"\\nSaved:\", out_csv)\n","print(\"Plots saved to:\", out_dir)"],"metadata":{"id":"u6TUXw4JRIu2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756837627826,"user_tz":-60,"elapsed":2157,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"fb7939cc-2263-457c-9ca6-03a81ec7227d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","=== Congruency Effect (Perfect Model) ===\n","RT overall: {'count': 1000.0, 'mean': 757.2537972876182, 'std': 181.32421719860798, 'min': 387.4115996252768, '25%': 633.2860700455742, '50%': 727.4402436018165, '75%': 867.9155825259757, '90%': 986.4138658246454, '95%': 1074.2149834421537, '99%': 1305.08941394862, 'max': 1735.1704025716751}\n","RT means by congruency (ms): inc=756.32 | con=758.10 | gap=-1.78\n","Cohen's d (inc - con): -0.010\n","Accuracy overall: 100.00% | by congruency (%):\n","is_congruent\n","incongruent    100.0\n","congruent      100.0\n","Entropy mean by congruency:\n","is_congruent\n","incongruent    0.003058\n","congruent      0.003017\n","k_samples mean by congruency:\n","is_congruent\n","incongruent    3.0\n","congruent      3.0\n","\n","--- vs Human targets (optional) ---\n","Human means: con=751.31 | inc=825.40 | gap=74.09 ms\n","Model deltas: Δcon=6.79 | Δinc=-69.08 | Δgap=-75.87 ms\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1915904000.py:107: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  plt.boxplot([rt_con, rt_inc], labels=[\"congruent\",\"incongruent\"])\n"]},{"output_type":"stream","name":"stdout","text":["\n","Saved: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/congruency_effect_perfect/gpt_perfect_pf_val_predictions_8resp_delta3_max100_RT_mapped_SHARED_congruency_stats.csv\n","Plots saved to: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/congruency_effect_perfect\n"]}]},{"cell_type":"markdown","source":["# WITHOUT CONTEXT"],"metadata":{"id":"ALwTtBx4HUEZ"}},{"cell_type":"markdown","source":["## Dataset Generation"],"metadata":{"id":"-89RlKnRHWk7"}},{"cell_type":"code","source":["# ============================================\n","# Perfect Model\n","# - Deterministic logic only (no noise)\n","# - Stimuli restricted to U/D/L/R\n","# - Vocab: U D L R A B C E 0 =>\n","# ============================================\n","\n","# ===== Imports =====\n","import os, csv, random\n","import numpy as np\n","from tqdm import tqdm\n","import pandas as pd\n","\n","# ===== Config =====\n","# I/O paths\n","LAYOUT_TXT  = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_layouts.txt\"\n","OUT_DIR     = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf_nocontext\" #*\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# Dataset parameters\n","NUM_TOTAL     = 10000       # number of sequences\n","VAL_RATIO     = 0.10        # 10% for validation\n","WINDOW_SIZE   = 1           # 1 trial -> 1*25 + '=>' + label #*\n","RNG_SEED      = 42          # reproducibility\n","\n","# Vocabulary\n","# V4-compatible: 8 extra tokens + placeholder + =>\n","# Only U/D/L/R are used as stimuli\n","VOCAB_TOKENS     = ['U','D','L','R','A','B','C','E']\n","DIRECTION_TOKENS = ['U','D','L','R']\n","PLACEHOLDER      = '0'\n","CONGRUENCY_RATIO = 0.5       # P(congruent) = 0.5\n","\n","TOKENS = VOCAB_TOKENS + [PLACEHOLDER, '=>']\n","stoi = {tok:i for i,tok in enumerate(TOKENS)}\n","itos = {i:tok for tok,i in stoi.items()}\n","\n","# ===== Seed =====\n","random.seed(RNG_SEED)\n","np.random.seed(RNG_SEED)\n","\n","# ===== Load symmetric layouts =====\n","SYMMETRIC_LAYOUTS = []\n","with open(LAYOUT_TXT, \"r\") as f:\n","    for line in f:\n","        s = line.strip()\n","        if not s:\n","            continue\n","        pos = tuple(map(int, s.split(',')))\n","        assert len(pos) == 5, f\"Layout length != 5: {pos}\"\n","        assert len(set(pos)) == 5, f\"Duplicate positions: {pos}\"\n","        assert all(0 <= p < 25 for p in pos), f\"Invalid position: {pos}\"\n","        SYMMETRIC_LAYOUTS.append(pos)\n","\n","print(f\"Loaded {len(SYMMETRIC_LAYOUTS)} layouts from file\")\n","\n","# ===== Helpers =====\n","def generate_centric_matrix_trial(layout, congruent=True):\n","    \"\"\"\n","    Create a 5x5 matrix (flattened to 25 tokens).\n","    - layout[2] is the target position\n","    - flankers occupy the other 4 positions\n","    - target/flankers restricted to U/D/L/R\n","    \"\"\"\n","    mat = [PLACEHOLDER] * 25\n","\n","    target_token = random.choice(DIRECTION_TOKENS)\n","\n","    if congruent:\n","        flanker_token = target_token\n","    else:\n","        choices = [t for t in DIRECTION_TOKENS if t != target_token]\n","        flanker_token = random.choice(choices)\n","\n","    for i, p in enumerate(layout):\n","        mat[p] = target_token if i == 2 else flanker_token\n","    return mat, target_token, congruent\n","\n","def encode_sequence(trials, label_token):\n","    \"\"\"\n","    Encode: 4 trials (4*25 tokens) + '=>' + label,\n","    mapped into token IDs.\n","    \"\"\"\n","    seq = []\n","    for t in trials:\n","        seq.extend(t)\n","    seq.append('=>')\n","    seq.append(label_token)\n","    return [stoi[t] for t in seq]\n","\n","# ===== Sequence generation =====\n","def generate_sequence_matrix(window_size=4):\n","    trials, layouts, flags, labels = [], [], [], []\n","    for _ in range(window_size):\n","        layout = random.choice(SYMMETRIC_LAYOUTS)\n","        is_cong = (random.random() < CONGRUENCY_RATIO)\n","        mat, tgt, flag = generate_centric_matrix_trial(layout, congruent=is_cong)\n","        # Perfect model: no corruption/noise\n","        trials.append(mat)\n","        layouts.append(layout)\n","        flags.append(flag)\n","        labels.append(tgt)\n","    return trials, labels[-1], layouts[-1], flags[-1]  # label/metadata from trial 4\n","\n","def generate_matrix_dataset(num_sequences=10000, window_size=4):\n","    seqs, layout4, flags4 = [], [], []\n","    for _ in tqdm(range(num_sequences), desc=\"Generating Perfect sequences\"):\n","        trials, label_tok, layout_last, cong_last = generate_sequence_matrix(window_size)\n","        token_ids = encode_sequence(trials, label_tok)\n","        seqs.append(token_ids)\n","        layout4.append(layout_last)\n","        flags4.append(cong_last)\n","    return seqs, layout4, flags4\n","\n","print(\"Generating dataset ...\")\n","all_sequences, all_layouts, all_congruents = generate_matrix_dataset(\n","    num_sequences=NUM_TOTAL,\n","    window_size=WINDOW_SIZE\n",")\n","\n","# ===== Shuffle & split =====\n","N = len(all_sequences)\n","perm = np.random.RandomState(RNG_SEED).permutation(N)\n","all_sequences = [all_sequences[i] for i in perm]\n","all_layouts   = [all_layouts[i]   for i in perm]\n","all_congruents= [all_congruents[i]for i in perm]\n","\n","split_idx = int(N * (1 - VAL_RATIO))\n","train_set, val_set = all_sequences[:split_idx], all_sequences[split_idx:]\n","train_layouts, val_layouts = all_layouts[:split_idx], all_layouts[split_idx:]\n","train_flags, val_flags     = all_congruents[:split_idx], all_congruents[split_idx:]\n","\n","# ===== Save .npy =====\n","np.save(os.path.join(OUT_DIR, 'train.npy'), np.array(train_set, dtype=np.int32))\n","np.save(os.path.join(OUT_DIR, 'val.npy'),   np.array(val_set,   dtype=np.int32))\n","print(f\"Saved .npy -> {OUT_DIR}\")\n","print(f\"train.npy: {len(train_set):,} | val.npy: {len(val_set):,}\")\n","\n","# ===== Save aligned meta =====\n","def layout_to_str(tup5):\n","    return \"-\".join(map(str, tup5))\n","\n","train_meta = pd.DataFrame({\n","    \"trial4_layout\":   [layout_to_str(t) for t in train_layouts],\n","    \"is_congruent\":    [int(f) for f in train_flags],\n","    \"seq_len\":         [len(s) for s in train_set],\n","})\n","val_meta = pd.DataFrame({\n","    \"trial4_layout\":   [layout_to_str(t) for t in val_layouts],\n","    \"is_congruent\":    [int(f) for f in val_flags],\n","    \"seq_len\":         [len(s) for s in val_set],\n","})\n","train_meta.to_csv(os.path.join(OUT_DIR, \"train_meta.csv\"), index=False)\n","val_meta.to_csv(os.path.join(OUT_DIR, \"val_meta.csv\"), index=False)\n","print(\"Saved aligned meta CSV\")\n","\n","# ===== Save combined CSV (optional preview) =====\n","combined_csv = os.path.join(OUT_DIR, \"flanker_matrix_perfect_pf_nocontext_preview.csv\") #*\n","with open(combined_csv, \"w\", newline=\"\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"trial_1_4_text\", \"target_response_token_id\", \"trial4_layout\", \"is_congruent\"])\n","    for token_ids, layout, flag in zip(all_sequences, all_layouts, all_congruents):\n","        text = \" \".join([itos[i] for i in token_ids[:-2]])\n","        target_id = token_ids[-1]\n","        layout_str = layout_to_str(layout)\n","        writer.writerow([text, target_id, layout_str, int(flag)])\n","print(f\"Preview CSV saved: {combined_csv}\")\n","\n","# ===== Save vocab =====\n","with open(os.path.join(OUT_DIR, \"vocab.txt\"), \"w\") as f:\n","    f.write(\",\".join(TOKENS))\n","print(\"Saved vocab.txt\")\n","\n","# ===== Sanity check =====\n","print(\"\\nSanity check:\")\n","print(\" - Example seq_len (should be 1*25+2 = 27):\", val_meta[\"seq_len\"].iloc[0] if len(val_meta) else \"N/A\") #*\n","print(\" - Expected block_size for training:\", \"27-1 = 26\") #*\n","print(\"\\n✅ DONE.\")"],"metadata":{"id":"-BKZHnXYDBrF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756837628312,"user_tz":-60,"elapsed":483,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"b3a1162b-45c9-4c9a-e623-7b21b48042ca"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 128 layouts from file\n","Generating dataset ...\n"]},{"output_type":"stream","name":"stderr","text":["Generating Perfect sequences: 100%|██████████| 10000/10000 [00:00<00:00, 58576.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved .npy -> /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf_nocontext\n","train.npy: 9,000 | val.npy: 1,000\n","Saved aligned meta CSV\n","Preview CSV saved: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf_nocontext/flanker_matrix_perfect_pf_nocontext_preview.csv\n","Saved vocab.txt\n","\n","Sanity check:\n"," - Example seq_len (should be 1*25+2 = 27): 27\n"," - Expected block_size for training: 27-1 = 26\n","\n","✅ DONE.\n"]}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"AJiheEe5HY8b"}},{"cell_type":"code","source":["# ============================================\n","# Train GPT-Flanker — Perfect Model (8 tokens)\n","# - Works for both context (seq_len=102) and no-context (seq_len=27)\n","# - Auto-detect block_size from dataset\n","# - Load vocab directly from dataset's vocab.txt\n","# ============================================\n","\n","# ===== Mount Google Drive =====\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ===== Imports =====\n","import os, sys\n","import torch\n","import numpy as np\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","\n","# Add path so Colab can locate model.py\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Flanker-GPT')\n","from model import GPT, GPTConfig\n","\n","# ===== Paths (update as needed) =====\n","data_dir = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/flanker_matrix_dataset_perfect_pf_nocontext\" #*\n","out_dir  = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/checkpoints\"\n","os.makedirs(out_dir, exist_ok=True)\n","\n","# ===== Reproducibility =====\n","random_seed = 42\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# ===== Load Dataset (.npy) =====\n","train_path = os.path.join(data_dir, 'train.npy')\n","val_path   = os.path.join(data_dir, 'val.npy')\n","assert os.path.exists(train_path) and os.path.exists(val_path), \"train.npy/val.npy not found in data_dir\"\n","\n","train_data = np.load(train_path)\n","val_data   = np.load(val_path)\n","\n","# Auto-detect sequence length & block_size\n","seq_len    = int(train_data.shape[1])     # includes label at the end\n","block_size = seq_len - 1                  # model input length (exclude label)\n","print(f\"seq_len = {seq_len} -> block_size = {block_size}\")\n","\n","# ===== Load Vocab =====\n","vocab_txt = os.path.join(data_dir, \"vocab.txt\")\n","with open(vocab_txt, \"r\") as f:\n","    TOKENS = f.read().strip().split(\",\")\n","stoi = {tok: i for i, tok in enumerate(TOKENS)}\n","itos = {i: tok for tok, i in stoi.items()}\n","vocab_size = len(TOKENS)\n","print(f\"Loaded vocab ({vocab_size} tokens): {TOKENS}\")\n","\n","# ===== Training Settings =====\n","device         = 'cuda' if torch.cuda.is_available() else 'cpu'\n","batch_size     = 64\n","max_iters      = 2000\n","eval_interval  = 200\n","learning_rate  = 3e-4\n","eval_batches   = 10  # batches used for quick loss estimate\n","\n","# ===== Mini dataloader =====\n","def get_batch(split):\n","    data = train_data if split == 'train' else val_data\n","    ix = np.random.randint(len(data), size=batch_size)\n","    # x = all but last token, y = last token (label)\n","    x = torch.tensor(np.stack([d[:-1] for d in data[ix]]), dtype=torch.long, device=device)\n","    y = torch.tensor([d[-1] for d in data[ix]], dtype=torch.long, device=device)\n","    return x, y\n","\n","# ===== Create Model =====\n","config = GPTConfig(\n","    vocab_size=vocab_size,\n","    block_size=block_size,\n","    n_layer=4,\n","    n_head=4,\n","    n_embd=128\n",")\n","model = GPT(config).to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","# ===== Eval helper =====\n","@torch.no_grad()\n","def estimate_loss():\n","    model.eval()\n","    out = {}\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_batches)\n","        for k in range(eval_batches):\n","            X, Y = get_batch(split)\n","            logits, _ = model(X)\n","            logits = logits[:, -1, :]  # predict final position only\n","            loss = F.cross_entropy(logits, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean().item()\n","    model.train()\n","    return out\n","\n","# ===== Training Loop =====\n","print(\"Training GPT-Flanker (Perfect Model, 8 tokens)...\")\n","for iter in range(max_iters):\n","    if iter % eval_interval == 0 or iter == max_iters - 1:\n","        losses = estimate_loss()\n","        print(f\"Step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    xb, yb = get_batch('train')\n","    logits, _ = model(xb)\n","    logits = logits[:, -1, :]         # predict only final token\n","    loss = F.cross_entropy(logits, yb)\n","\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    # Optional: gradient clipping to avoid exploding gradients\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    optimizer.step()\n","\n","# ===== Save Model Checkpoint =====\n","# Name checkpoint clearly to indicate perfect + context/no-context\n","ckpt_name = \"flanker_gpt_matrix_perfect_pf_nocontext.pt\"  #*\n","ckpt_path = os.path.join(out_dir, ckpt_name)\n","torch.save(model.state_dict(), ckpt_path)\n","print(f\"✅ Model saved to {ckpt_path}\")"],"metadata":{"id":"YuYVb9Z8F18f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756837652855,"user_tz":-60,"elapsed":24541,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"ca605b5e-90dd-49b1-80b5-f9b6163b5753"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","seq_len = 27 -> block_size = 26\n","Loaded vocab (10 tokens): ['U', 'D', 'L', 'R', 'A', 'B', 'C', 'E', '0', '=>']\n","number of parameters: 0.79M\n","Training GPT-Flanker (Perfect Model, 8 tokens)...\n","Step 0: train loss 2.4496, val loss 2.4511\n","Step 200: train loss 0.0233, val loss 0.0218\n","Step 400: train loss 0.0036, val loss 0.0036\n","Step 600: train loss 0.0017, val loss 0.0017\n","Step 800: train loss 0.0010, val loss 0.0010\n","Step 1000: train loss 0.0007, val loss 0.0007\n","Step 1200: train loss 0.0005, val loss 0.0005\n","Step 1400: train loss 0.0004, val loss 0.0004\n","Step 1600: train loss 0.0003, val loss 0.0003\n","Step 1800: train loss 0.0002, val loss 0.0002\n","Step 1999: train loss 0.0002, val loss 0.0002\n","✅ Model saved to /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/checkpoints/flanker_gpt_matrix_perfect_pf_nocontext.pt\n"]}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"f9kUTdtDHaIB"}},{"cell_type":"code","source":["# ============================================\n","# Evaluate GPT-Flanker — Perfect Model (8 tokens)\n","# - Responses allowed: U/D/L/R/A/B/C/E\n","# - Loads vocab from dataset\n","# - Works for both context and no-context automatically\n","# ============================================\n","\n","# ===== Imports =====\n","import os, sys, csv\n","import torch\n","import numpy as np\n","import torch.nn.functional as F\n","import pandas as pd\n","\n","# ===== Add model path =====\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Flanker-GPT')\n","from model import GPT, GPTConfig\n","\n","# ===== Settings =====\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Stopping-rule parameters\n","delta = 3\n","max_samples = 100\n","restrict_to_response_tokens = True  # restrict predictions to U/D/L/R/A/B/C/E\n","\n","# ===== Paths (update as needed) =====\n","base_dir      = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT\"\n","data_dir      = f\"{base_dir}/flanker_matrix_dataset_perfect_pf_nocontext\" #*\n","ckpt_path     = f\"{base_dir}/checkpoints/flanker_gpt_matrix_perfect_pf_nocontext.pt\" #*\n","val_path      = os.path.join(data_dir, \"val.npy\")\n","val_meta_path = os.path.join(data_dir, \"val_meta.csv\")\n","output_csv    = f\"{base_dir}/gpt_perfect_pf_nocontext_val_predictions_8resp_delta{delta}_max{max_samples}.csv\" #*\n","\n","# ===== Load Vocab =====\n","vocab_txt = os.path.join(data_dir, \"vocab.txt\")\n","assert os.path.exists(vocab_txt), f\"vocab.txt not found: {vocab_txt}\"\n","with open(vocab_txt, \"r\") as f:\n","    TOKENS = f.read().strip().split(\",\")\n","\n","itos = {i: ch for i, ch in enumerate(TOKENS)}\n","stoi = {ch: i for i, ch in enumerate(TOKENS)}\n","vocab_size = len(TOKENS)\n","\n","# Responses restricted to the 8 stimulus tokens\n","response_tokens = [t for t in TOKENS if t not in ['0','=>']]\n","response_token_ids = [stoi[t] for t in response_tokens]\n","\n","print(f\"Loaded vocab ({vocab_size}): {TOKENS}\")\n","print(f\"Response tokens used for prediction (8): {response_tokens}\")\n","\n","# ===== Load Validation Data =====\n","assert os.path.exists(val_path), f\"val.npy not found: {val_path}\"\n","val_data = np.load(val_path)\n","num_val = len(val_data)\n","block_size = val_data.shape[1] - 1\n","print(f\"Loaded {num_val} validation samples | inferred block_size={block_size}\")\n","\n","# ===== Load aligned meta (val_meta.csv) =====\n","assert os.path.exists(val_meta_path), f\"val_meta.csv not found: {val_meta_path}\"\n","meta = pd.read_csv(val_meta_path)\n","assert len(meta) == num_val, f\"val_meta rows ({len(meta)}) != VAL size ({num_val})\"\n","\n","# ===== Load Trained Model =====\n","config = GPTConfig(vocab_size=vocab_size, block_size=block_size, n_layer=4, n_head=4, n_embd=128)\n","model = GPT(config).to(device)\n","model.load_state_dict(torch.load(ckpt_path, map_location=device))\n","model.eval()\n","print(\"✅ Loaded Perfect GPT Model\")\n","\n","# ===== Utils =====\n","def calculate_entropy(prob_dist_np):\n","    return -float(np.sum(prob_dist_np * np.log(prob_dist_np + 1e-12)))\n","\n","def sample_until_threshold(probs_full, delta=3, max_samples=100, restrict_ids=None):\n","    \"\"\"\n","    Sequential sampling until the gap between top and second counts >= delta.\n","    \"\"\"\n","    if restrict_ids is not None:\n","        sub = probs_full[restrict_ids]\n","        sub = sub / sub.sum()\n","        id_map = restrict_ids\n","        def draw():\n","            return id_map[torch.multinomial(sub, num_samples=1, replacement=True).item()]\n","    else:\n","        def draw():\n","            return torch.multinomial(probs_full, num_samples=1, replacement=True).item()\n","\n","    counts = {}\n","    for s in range(1, max_samples + 1):\n","        tok = draw()\n","        counts[tok] = counts.get(tok, 0) + 1\n","        sorted_pairs = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)\n","        top = sorted_pairs[0][1]\n","        second = sorted_pairs[1][1] if len(sorted_pairs) > 1 else 0\n","        gap = top - second\n","        if gap >= delta:\n","            return sorted_pairs[0][0], s, True, gap\n","\n","    # fallback: argmax over restricted or full distribution\n","    if restrict_ids is not None:\n","        winner_id = restrict_ids[torch.argmax(probs_full[restrict_ids]).item()]\n","    else:\n","        winner_id = torch.argmax(probs_full).item()\n","\n","    if counts:\n","        sorted_pairs = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)\n","        gap = sorted_pairs[0][1] - (sorted_pairs[1][1] if len(sorted_pairs) > 1 else 0)\n","    else:\n","        gap = 0\n","    return winner_id, max_samples, False, gap\n","\n","# ===== Evaluation =====\n","results = []\n","correct = 0\n","\n","for i in range(num_val):\n","    x = torch.tensor(val_data[i][:-1], dtype=torch.long, device=device).unsqueeze(0)\n","    true_id = int(val_data[i][-1])\n","    true_tok = itos[true_id]\n","\n","    with torch.no_grad():\n","        logits, _ = model(x)\n","        probs = F.softmax(logits[:, -1, :], dim=-1).squeeze(0).cpu()\n","\n","        winner_id, k_used, stopped, gap_at_stop = sample_until_threshold(\n","            probs_full=probs,\n","            delta=delta,\n","            max_samples=max_samples,\n","            restrict_ids=response_token_ids if restrict_to_response_tokens else None\n","        )\n","\n","        pred_tok = itos[winner_id]\n","        is_correct = (winner_id == true_id)\n","        if is_correct:\n","            correct += 1\n","\n","        confidence = float(probs[winner_id].item())\n","        prob_true  = float(probs[true_id].item())\n","        entropy    = calculate_entropy(probs.numpy())\n","\n","    # aligned meta info\n","    is_congruent  = int(meta.loc[i, \"is_congruent\"])\n","    trial4_layout = meta.loc[i, \"trial4_layout\"]\n","\n","    row = {\n","        \"example\": i + 1,\n","        \"true_response\": true_tok,\n","        \"predicted_response\": pred_tok,\n","        \"is_correct\": bool(is_correct),\n","\n","        \"confidence\": round(confidence, 6),\n","        \"prob_of_true_token\": round(prob_true, 6),\n","        \"entropy\": round(entropy, 6),\n","\n","        \"k_samples\": int(k_used),\n","        \"stopped_by_delta\": bool(stopped),\n","        \"gap_at_stop\": int(gap_at_stop),\n","        \"delta\": int(delta),\n","        \"max_samples\": int(max_samples),\n","\n","        \"is_congruent\": is_congruent,\n","        \"trial4_layout\": trial4_layout,\n","    }\n","\n","    # record probabilities for all vocab tokens\n","    for tok in TOKENS:\n","        row[f\"{tok}_prob\"] = round(float(probs[stoi[tok]].item()), 6)\n","\n","    results.append(row)\n","\n","# ===== Save Results =====\n","with open(output_csv, \"w\", newline=\"\") as f:\n","    writer = csv.DictWriter(f, fieldnames=list(results[0].keys()))\n","    writer.writeheader()\n","    writer.writerows(results)\n","\n","acc = correct / num_val\n","print(\"\\n✅ Stopping-rule evaluation complete.\")\n","print(f\"Accuracy = {acc * 100:.2f}% (Δ={delta}, max={max_samples})\")\n","print(f\"Saved to: {output_csv}\")"],"metadata":{"id":"4OT4kHwKTnlV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756837655293,"user_tz":-60,"elapsed":2414,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"4edae8e4-2ac6-48dc-b20c-1405099155f8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded vocab (10): ['U', 'D', 'L', 'R', 'A', 'B', 'C', 'E', '0', '=>']\n","Response tokens used for prediction (8): ['U', 'D', 'L', 'R', 'A', 'B', 'C', 'E']\n","Loaded 1000 validation samples | inferred block_size=26\n","number of parameters: 0.79M\n","✅ Loaded Perfect GPT Model\n","\n","✅ Stopping-rule evaluation complete.\n","Accuracy = 100.00% (Δ=3, max=100)\n","Saved to: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100.csv\n"]}]},{"cell_type":"markdown","source":["### Evaluation Analysis"],"metadata":{"id":"8Hkuc10uHbfv"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# ===== Path to evaluation results =====\n","csv_path = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100.csv\" #*\n","\n","df = pd.read_csv(csv_path)\n","print(\"Rows:\", len(df))\n","print(\"Columns:\", list(df.columns))\n","\n","# ===== Check required columns =====\n","required = [\n","    \"is_congruent\", \"k_samples\", \"stopped_by_delta\", \"gap_at_stop\",\n","    \"is_correct\", \"entropy\", \"confidence\", \"delta\", \"max_samples\"\n","]\n","missing = [c for c in required if c not in df.columns]\n","print(\"Missing required columns:\", missing)\n","\n","# ===== Overall accuracy =====\n","acc_overall = df[\"is_correct\"].mean()\n","print(f\"\\nAccuracy overall: {acc_overall*100:.2f}%\")\n","\n","# ===== Helper: summarize k_samples =====\n","def summarize_k(x):\n","    q = x.quantile([0, .25, .5, .75, .95, .99]).to_dict()\n","    return {\n","        \"count\": int(x.count()),\n","        \"min\": float(x.min()),\n","        \"mean\": float(x.mean()),\n","        \"std\": float(x.std(ddof=1)),\n","        \"p25\": float(q[0.25]),\n","        \"p50\": float(q[0.5]),\n","        \"p75\": float(q[0.75]),\n","        \"p95\": float(q[0.95]),\n","        \"p99\": float(q[0.99]),\n","        \"max\": float(x.max()),\n","    }\n","\n","# ===== k_samples summaries =====\n","print(\"\\n== k_samples summary (overall) ==\")\n","print(summarize_k(df[\"k_samples\"]))\n","\n","print(\"\\n== k_samples summary by congruency ==\")\n","for flag, g in df.groupby(\"is_congruent\"):\n","    label = \"congruent\" if flag == 1 else \"incongruent\"\n","    print(f\"\\n[{label}] n={len(g)}\")\n","    print(\"Accuracy:\", round(g[\"is_correct\"].mean()*100, 2), \"%\")\n","    print(\"Entropy mean:\", round(g[\"entropy\"].mean(), 4))\n","    print(summarize_k(g[\"k_samples\"]))\n","\n","# ===== Stopping diagnostics =====\n","stop_rate = df[\"stopped_by_delta\"].mean()\n","hit_max = (df[\"k_samples\"] >= df[\"max_samples\"]).mean()\n","print(f\"\\nStopped by threshold (rate): {stop_rate*100:.2f}%\")\n","print(f\"Hit max_samples (rate): {hit_max*100:.2f}%\")\n","\n","# ===== Correlations =====\n","def safe_corr(a, b):\n","    if a.std(ddof=1) == 0 or b.std(ddof=1) == 0:\n","        return np.nan\n","    return float(np.corrcoef(a, b)[0, 1])\n","\n","corr_k_entropy = safe_corr(df[\"k_samples\"], df[\"entropy\"])\n","corr_k_one_minus_conf = safe_corr(df[\"k_samples\"], 1 - df[\"confidence\"])\n","print(f\"\\nCorr(k, entropy): {corr_k_entropy:.3f}\")\n","print(f\"Corr(k, 1-confidence): {corr_k_one_minus_conf:.3f}\")\n","\n","# ===== Predicted response distribution =====\n","if \"predicted_response\" in df.columns:\n","    print(\"\\nPredicted response counts (top 10):\")\n","    print(df[\"predicted_response\"].value_counts().head(10))\n","\n","# ===== Save a 100-row sample (for quick sharing/inspection) =====\n","sample_path = csv_path.replace(\".csv\", \"_SAMPLE100.csv\")\n","df.head(100).to_csv(sample_path, index=False)\n","print(\"\\nSaved sample to:\", sample_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KP8IWIBEHclH","executionInfo":{"status":"ok","timestamp":1756837655584,"user_tz":-60,"elapsed":289,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"0c9d7e57-31a1-4df6-aa86-a4a58bb454dd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Rows: 1000\n","Columns: ['example', 'true_response', 'predicted_response', 'is_correct', 'confidence', 'prob_of_true_token', 'entropy', 'k_samples', 'stopped_by_delta', 'gap_at_stop', 'delta', 'max_samples', 'is_congruent', 'trial4_layout', 'U_prob', 'D_prob', 'L_prob', 'R_prob', 'A_prob', 'B_prob', 'C_prob', 'E_prob', '0_prob', '=>_prob']\n","Missing required columns: []\n","\n","Accuracy overall: 100.00%\n","\n","== k_samples summary (overall) ==\n","{'count': 1000, 'min': 3.0, 'mean': 3.0, 'std': 0.0, 'p25': 3.0, 'p50': 3.0, 'p75': 3.0, 'p95': 3.0, 'p99': 3.0, 'max': 3.0}\n","\n","== k_samples summary by congruency ==\n","\n","[incongruent] n=467\n","Accuracy: 100.0 %\n","Entropy mean: 0.0023\n","{'count': 467, 'min': 3.0, 'mean': 3.0, 'std': 0.0, 'p25': 3.0, 'p50': 3.0, 'p75': 3.0, 'p95': 3.0, 'p99': 3.0, 'max': 3.0}\n","\n","[congruent] n=533\n","Accuracy: 100.0 %\n","Entropy mean: 0.0022\n","{'count': 533, 'min': 3.0, 'mean': 3.0, 'std': 0.0, 'p25': 3.0, 'p50': 3.0, 'p75': 3.0, 'p95': 3.0, 'p99': 3.0, 'max': 3.0}\n","\n","Stopped by threshold (rate): 100.00%\n","Hit max_samples (rate): 0.00%\n","\n","Corr(k, entropy): nan\n","Corr(k, 1-confidence): nan\n","\n","Predicted response counts (top 10):\n","predicted_response\n","U    268\n","R    257\n","L    238\n","D    237\n","Name: count, dtype: int64\n","\n","Saved sample to: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100_SAMPLE100.csv\n"]}]},{"cell_type":"markdown","source":["### RT Mapping (Shared Parameters)"],"metadata":{"id":"MaGqoGJh1vTZ"}},{"cell_type":"code","source":["# ===========================================\n","# RT Mapping with SHARED parameters (no per-condition fitting)\n","# - Uses pooled t0, theta_shared, dispersion_shared\n","# ===========================================\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","# ---------- INPUT ----------\n","in_csv = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100.csv\" #*\n","\n","# ---------- SHARED PARAMS (fixed across models & conditions) ----------\n","# If already defined upstream, reuse: t0, theta_shared, dispersion_shared\n","try:\n","    t0              # check if defined earlier\n","    theta_shared\n","    dispersion_shared\n","    dispersion = float(dispersion_shared)\n","except NameError:\n","    # Fallback fixed values (replace with your calibrated ones if available)\n","    t0 = 300.0               # non-decision time (ms)\n","    theta_shared = 151.0837  # ms per sample (from pooled Plan B)\n","    dispersion = 2.25        # controls variance (fallback or calibrated value)\n","\n","t0_jitter_sd = 0.0           # optional Gaussian jitter on t0\n","use_erlang = True            # True = Gamma/Erlang RT, False = linear deterministic\n","\n","# ---------- LOAD ----------\n","df = pd.read_csv(in_csv)\n","assert \"k_samples\" in df.columns, \"CSV must contain column k_samples\"\n","\n","# ---------- MAP RT ----------\n","rng = np.random.default_rng(20250809)\n","\n","def draw_rt_row(row):\n","    k = int(max(1, row[\"k_samples\"]))\n","    t0_eff = t0 + (rng.normal(0, t0_jitter_sd) if t0_jitter_sd > 0 else 0.0)\n","    if not use_erlang:\n","        # Linear deterministic mapping\n","        return float(t0_eff + k * theta_shared)\n","    # Erlang/Gamma with dispersion control:\n","    # mean = k*theta_shared, var = theta_shared^2 * (k/dispersion)\n","    shape = k * dispersion\n","    scale = theta_shared / dispersion\n","    return float(t0_eff + rng.gamma(shape=shape, scale=scale))\n","\n","df[\"rt_ms\"] = df.apply(draw_rt_row, axis=1)\n","\n","# Optional: clip to human RT reporting range\n","# df[\"rt_ms\"] = df[\"rt_ms\"].clip(150, 3000)\n","\n","# ---------- SAVE ----------\n","suffix = \"RT_mapped_SHARED\"\n","out_csv = os.path.splitext(in_csv)[0] + f\"{suffix}.csv\"\n","df.to_csv(out_csv, index=False)\n","\n","# ---------- QUICK SUMMARY ----------\n","def summarize(s):\n","    d = s.describe(percentiles=[.25, .5, .75, .9, .95, .99])\n","    return {k: float(d[k]) for k in d.index}\n","\n","overall_pred = summarize(df[\"rt_ms\"])\n","\n","means_by_c = {}\n","gap_pred = float(\"nan\")\n","if \"is_congruent\" in df.columns:\n","    means_by_c = df.groupby(\"is_congruent\")[\"rt_ms\"].mean().to_dict()\n","    gap_pred = means_by_c.get(0, np.nan) - means_by_c.get(1, np.nan)\n","\n","print(\"\\n=== Predicted RT (SHARED params) ===\")\n","print(f\"t0 = {t0:.1f} ms | theta_shared = {theta_shared:.4f} | dispersion = {dispersion:.4f}\")\n","print(\"Overall:\", overall_pred)\n","if means_by_c:\n","    print(f\"Means by congruency: inc={means_by_c.get(0, np.nan):.2f} | con={means_by_c.get(1, np.nan):.2f} | gap={gap_pred:.2f} ms\")\n","print(\"Saved:\", out_csv)"],"metadata":{"id":"tRuDXhl7QTP9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756837655592,"user_tz":-60,"elapsed":19,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"b7a803fd-8250-4d78-f5c5-d8c7ff39391e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Predicted RT (SHARED params) ===\n","t0 = 300.0 ms | theta_shared = 150.9809 | dispersion = 2.2500\n","Overall: {'count': 1000.0, 'mean': 757.2537972876182, 'std': 181.32421719860798, 'min': 387.41159962527684, '25%': 633.2860700455742, '50%': 727.4402436018165, '75%': 867.9155825259757, '90%': 986.4138658246454, '95%': 1074.2149834421537, '99%': 1305.0894139486202, 'max': 1735.1704025716751}\n","Means by congruency: inc=751.99 | con=761.86 | gap=-9.87 ms\n","Saved: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100RT_mapped_SHARED.csv\n"]}]},{"cell_type":"markdown","source":["### Congruency Effect Analysis"],"metadata":{"id":"QNwsp11eHea6"}},{"cell_type":"code","source":["# ===========================================\n","# Analyze Congruency Effect — Perfect Model\n","# Requires: evaluation results (with stopping rule) + RT mapping (rt_ms column)\n","# ===========================================\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, numpy as np, pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# ---------- INPUT ----------\n","base_dir = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT\"\n","pred_csv = f\"{base_dir}/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100_RT_mapped_SHARED.csv\" #*\n","out_dir  = os.path.join(base_dir, \"congruency_effect_perfect_nocontext\") #*\n","os.makedirs(out_dir, exist_ok=True)\n","\n","# Optional: human reference values for comparison\n","mu_con_human = 751.31\n","mu_inc_human = 825.40\n","\n","# ---------- LOAD ----------\n","df = pd.read_csv(pred_csv)\n","req = {\"is_congruent\",\"rt_ms\",\"is_correct\",\"entropy\",\"confidence\",\"k_samples\"}\n","missing = list(req - set(df.columns))\n","assert not missing, f\"Missing columns: {missing}\"\n","\n","# ---------- BASIC SUMMARIES ----------\n","def summ(x: pd.Series):\n","    d = x.describe(percentiles=[.25,.5,.75,.9,.95,.99])\n","    return {k: float(d[k]) for k in d.index}\n","\n","overall_rt = summ(df[\"rt_ms\"])\n","by_c = df.groupby(\"is_congruent\")[\"rt_ms\"].mean().to_dict()\n","gap_ms = by_c.get(0, np.nan) - by_c.get(1, np.nan)\n","\n","acc_overall = float(df[\"is_correct\"].mean()*100)\n","acc_by_c = (df.groupby(\"is_congruent\")[\"is_correct\"]\n","              .mean()\n","              .rename({0:\"incongruent\",1:\"congruent\"})*100)\n","\n","ent_by_c = df.groupby(\"is_congruent\")[\"entropy\"].mean().rename({0:\"incongruent\",1:\"congruent\"})\n","k_by_c   = df.groupby(\"is_congruent\")[\"k_samples\"].mean().rename({0:\"incongruent\",1:\"congruent\"})\n","\n","def cohens_d(a, b):\n","    a = np.asarray(a, dtype=float); b = np.asarray(b, dtype=float)\n","    if len(a)<2 or len(b)<2: return np.nan\n","    m1, m2 = a.mean(), b.mean()\n","    s1, s2 = a.std(ddof=1), b.std(ddof=1)\n","    sp = np.sqrt(((len(a)-1)*s1*s1 + (len(b)-1)*s2*s2)/(len(a)+len(b)-2))\n","    return (m1-m2)/sp if sp>0 else np.nan\n","\n","rt_inc = df.loc[df[\"is_congruent\"]==0, \"rt_ms\"].values\n","rt_con = df.loc[df[\"is_congruent\"]==1, \"rt_ms\"].values\n","d_eff  = cohens_d(rt_inc, rt_con)\n","\n","print(\"=== Congruency Effect (Perfect Model) ===\")\n","print(\"RT overall:\", overall_rt)\n","print(f\"RT means by congruency (ms): inc={by_c.get(0, np.nan):.2f} | con={by_c.get(1, np.nan):.2f} | gap={gap_ms:.2f}\")\n","print(f\"Cohen's d (inc - con): {d_eff:.3f}\")\n","print(f\"Accuracy overall: {acc_overall:.2f}% | by congruency (%):\\n{acc_by_c.to_string()}\")\n","print(f\"Entropy mean by congruency:\\n{ent_by_c.to_string()}\")\n","print(f\"k_samples mean by congruency:\\n{k_by_c.to_string()}\")\n","\n","# ---------- Optional: compare with human ----------\n","print(\"\\n--- vs Human targets (optional) ---\")\n","human_gap = mu_inc_human - mu_con_human\n","print(f\"Human means: con={mu_con_human:.2f} | inc={mu_inc_human:.2f} | gap={human_gap:.2f} ms\")\n","print(f\"Model deltas: Δcon={by_c.get(1, np.nan)-mu_con_human:.2f} | Δinc={by_c.get(0, np.nan)-mu_inc_human:.2f} | Δgap={gap_ms - human_gap:.2f} ms\")\n","\n","# ---------- SAVE TABLE ----------\n","rows = [\n","    {\"metric\":\"RT_overall\", **overall_rt},\n","    {\"metric\":\"RT_mean_congruent\", \"mean\": by_c.get(1, np.nan)},\n","    {\"metric\":\"RT_mean_incongruent\", \"mean\": by_c.get(0, np.nan)},\n","    {\"metric\":\"RT_gap_inc_minus_con\", \"gap_ms\": gap_ms},\n","    {\"metric\":\"Cohens_d_inc_minus_con\", \"d\": d_eff},\n","    {\"metric\":\"Accuracy_overall_%\", \"value\": acc_overall},\n","    {\"metric\":\"Accuracy_congruent_%\", \"value\": acc_by_c.get(\"congruent\", np.nan)},\n","    {\"metric\":\"Accuracy_incongruent_%\", \"value\": acc_by_c.get(\"incongruent\", np.nan)},\n","    {\"metric\":\"Entropy_mean_congruent\", \"value\": ent_by_c.get(\"congruent\", np.nan)},\n","    {\"metric\":\"Entropy_mean_incongruent\", \"value\": ent_by_c.get(\"incongruent\", np.nan)},\n","    {\"metric\":\"k_mean_congruent\", \"value\": k_by_c.get(\"congruent\", np.nan)},\n","    {\"metric\":\"k_mean_incongruent\", \"value\": k_by_c.get(\"incongruent\", np.nan)},\n","]\n","out_csv = os.path.join(out_dir, os.path.basename(pred_csv).replace(\".csv\",\"_congruency_stats.csv\"))\n","pd.DataFrame(rows).to_csv(out_csv, index=False)\n","\n","# ---------- PLOTS ----------\n","plt.figure(figsize=(6,4))\n","plt.hist(df.loc[df[\"is_congruent\"]==1, \"rt_ms\"], bins=60, alpha=0.6, label=\"congruent\")\n","plt.hist(df.loc[df[\"is_congruent\"]==0, \"rt_ms\"], bins=60, alpha=0.6, label=\"incongruent\")\n","plt.xlabel(\"RT (ms)\"); plt.ylabel(\"Count\"); plt.title(\"RT by Congruency (Histogram)\")\n","plt.legend(); plt.tight_layout()\n","plt.savefig(os.path.join(out_dir,\"rt_hist_by_congruency.png\"), dpi=160); plt.close()\n","\n","def ecdf(x):\n","    xs = np.sort(x); ys = np.arange(1, len(xs)+1)/len(xs); return xs, ys\n","x1,y1 = ecdf(rt_con); x2,y2 = ecdf(rt_inc)\n","plt.figure(figsize=(6,4))\n","plt.plot(x1,y1,label=\"congruent\"); plt.plot(x2,y2,label=\"incongruent\")\n","plt.xlabel(\"RT (ms)\"); plt.ylabel(\"CDF\"); plt.title(\"RT CDF by Congruency\")\n","plt.legend(); plt.tight_layout()\n","plt.savefig(os.path.join(out_dir,\"rt_cdf_by_congruency.png\"), dpi=160); plt.close()\n","\n","plt.figure(figsize=(5,4))\n","plt.boxplot([rt_con, rt_inc], labels=[\"congruent\",\"incongruent\"])\n","plt.ylabel(\"RT (ms)\"); plt.title(\"RT Boxplot by Congruency\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(out_dir,\"rt_box_by_congruency.png\"), dpi=160); plt.close()\n","\n","print(\"\\nSaved:\", out_csv)\n","print(\"Plots saved to:\", out_dir)"],"metadata":{"id":"mD3NQFg7RUyR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756837657649,"user_tz":-60,"elapsed":2055,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"8ca3f8f0-d62c-420b-b411-f7589834627b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","=== Congruency Effect (Perfect Model) ===\n","RT overall: {'count': 1000.0, 'mean': 757.5650371483999, 'std': 181.44763951779265, 'min': 387.4710982543958, '25%': 633.5129285444141, '50%': 727.7311902111182, '75%': 868.3021467664253, '90%': 986.8810885296402, '95%': 1074.7419699102616, '99%': 1305.7735501791472, 'max': 1736.1472828927226}\n","RT means by congruency (ms): inc=752.30 | con=762.18 | gap=-9.88\n","Cohen's d (inc - con): -0.054\n","Accuracy overall: 100.00% | by congruency (%):\n","is_congruent\n","incongruent    100.0\n","congruent      100.0\n","Entropy mean by congruency:\n","is_congruent\n","incongruent    0.002258\n","congruent      0.002220\n","k_samples mean by congruency:\n","is_congruent\n","incongruent    3.0\n","congruent      3.0\n","\n","--- vs Human targets (optional) ---\n","Human means: con=751.31 | inc=825.40 | gap=74.09 ms\n","Model deltas: Δcon=10.87 | Δinc=-73.10 | Δgap=-83.97 ms\n","\n","Saved: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/congruency_effect_perfect_nocontext/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100_RT_mapped_SHARED_congruency_stats.csv\n","Plots saved to: /content/drive/MyDrive/Colab Notebooks/Flanker-GPT/congruency_effect_perfect_nocontext\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2492017945.py:107: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  plt.boxplot([rt_con, rt_inc], labels=[\"congruent\",\"incongruent\"])\n"]}]},{"cell_type":"markdown","source":["# Erlang Distribution"],"metadata":{"id":"brODwuXVKmYW"}},{"cell_type":"code","source":["# === RT distributions (clipped) — Human vs 1 Model (context & no-context) ===\n","# Provide paths for 3 inputs: human train/val meta, and 2 model CSVs (ctx & no-ctx)\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# ---------- PATHS (fill in accordingly) ----------\n","HUMAN_META_TRAIN = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/human_dataset/train_meta.csv\"   # << path to human train meta\n","HUMAN_META_VAL   = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/human_dataset/val_meta.csv\"     # << path to human val meta\n","\n","MODEL_CTX_CSV    = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_val_predictions_8resp_delta3_max100_RT_mapped_SHARED.csv\"     # << path to model (context)\n","MODEL_NOCTX_CSV  = \"/content/drive/MyDrive/Colab Notebooks/Flanker-GPT/gpt_perfect_pf_nocontext_val_predictions_8resp_delta3_max100_RT_mapped_SHARED.csv\"  # << path to model (no-context)\n","\n","CLIP_LO, CLIP_HI = 150, 3000  # clipping range (same as human baseline)\n","\n","# ---------- helpers ----------\n","def clip_series(s, lo, hi):\n","    return s[(s >= lo) & (s <= hi)]\n","\n","def load_human_rt(train_meta_path, val_meta_path, lo, hi):\n","    meta = pd.concat([pd.read_csv(train_meta_path), pd.read_csv(val_meta_path)], ignore_index=True)\n","    assert \"trial4_response_time\" in meta.columns, \"Human meta must contain column: trial4_response_time\"\n","    rt = meta[\"trial4_response_time\"].dropna().astype(float)\n","    rt = clip_series(rt, lo, hi)\n","    return rt.values\n","\n","def load_model_rt(csv_path, lo, hi):\n","    df = pd.read_csv(csv_path)\n","    assert \"rt_ms\" in df.columns, f\"{csv_path} must contain column: rt_ms\"\n","    rt = clip_series(df[\"rt_ms\"].astype(float), lo, hi)\n","    return rt.values\n","\n","# ---------- load ----------\n","human_rt  = load_human_rt(HUMAN_META_TRAIN, HUMAN_META_VAL, CLIP_LO, CLIP_HI)\n","model_ctx = load_model_rt(MODEL_CTX_CSV,   CLIP_LO, CLIP_HI)\n","model_nc  = load_model_rt(MODEL_NOCTX_CSV, CLIP_LO, CLIP_HI)\n","\n","# ---------- plot (PDF via histogram density) ----------\n","plt.figure(figsize=(8,5))\n","plt.hist(human_rt,  bins=60, range=(CLIP_LO,CLIP_HI), density=True, histtype=\"step\", linewidth=1.5, label=\"Human Logs (Baseline)\")\n","plt.hist(model_ctx, bins=60, range=(CLIP_LO,CLIP_HI), density=True, histtype=\"step\", linewidth=1.2, label=\"Perfect Model (ctx)\")\n","plt.hist(model_nc,  bins=60, range=(CLIP_LO,CLIP_HI), density=True, histtype=\"step\", linewidth=1.2, label=\"Perfect Model (no-ctx)\")\n","plt.xlabel(f\"RT (ms) — clipped to [{CLIP_LO}, {CLIP_HI}]\")\n","plt.ylabel(\"Density\")\n","plt.title(\"RT distributions (Erlang-mapped) vs Human (clipped)\")\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n","\n","# ---------- quick summary (quantiles) ----------\n","def qtxt(a):\n","    return dict(p10=float(np.percentile(a,10)), p50=float(np.percentile(a,50)), p90=float(np.percentile(a,90)))\n","\n","print(\"Quantiles (clipped):\")\n","print(\"Human Logs      :\", qtxt(human_rt))\n","print(\"Perfect Model (ctx) :\", qtxt(model_ctx))\n","print(\"Perfect Model (no-ctx):\", qtxt(model_nc))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"id":"_q7MugE8ricm","executionInfo":{"status":"ok","timestamp":1756837746093,"user_tz":-60,"elapsed":4253,"user":{"displayName":"Peerasit Srisukontamit","userId":"15163058641388219245"}},"outputId":"7b99487f-6350-4a48-e99c-cb466607da92"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Quantiles (clipped):\n","Human Logs      : {'p10': 592.0, 'p50': 746.0, 'p90': 1027.0}\n","Perfect Model (ctx) : {'p10': 547.5711898900105, 'p50': 727.4402436018165, 'p90': 986.4138658246454}\n","Perfect Model (no-ctx): {'p10': 547.7397046691814, 'p50': 727.7311902111182, 'p90': 986.8810885296402}\n"]}]}]}